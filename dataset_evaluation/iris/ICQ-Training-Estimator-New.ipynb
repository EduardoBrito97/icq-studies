{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7247aa79",
   "metadata": {},
   "source": [
    "## Experimenting agains Iris dataset - Modified ICQ Method\n",
    "\n",
    "Runs the modified ICQ classifier against Iris dataset, using Stratified 10-Fold cross validation throughout many different random seeds to validate the classifier. At the end of each 10-Fold cross validation, it prints the AVG score and F1-Score for the classifier - and after executing with all different random seeds, the average score/f1-score is also printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a44568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "sys.path.append(os.path.abspath('../../models'))\n",
    "sys.path.append(os.path.abspath('../../helpers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e369ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers.utils import print_metrics, executeIrisOneVsRest\n",
    "from helpers.icq_methods import create_and_execute_classifier_new_approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "822d41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# We're ignoring some warning from sklearn.metrics.classification_report\n",
    "warnings.simplefilter(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6c3aad8",
   "metadata": {},
   "source": [
    "## Sigma_Q param = [1, 1, 1, 0]\n",
    "We're first executing this test for different seeds using the same sigma Q as the original one, but with the new approach (having weights on U operator and inputs on rho env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db20f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: Scores = 0.9199999999999999 F1-Scores = 0.9176347726347727\n",
      "AVG: Scores = 0.9533333333333335 F1-Scores = 0.9525757575757575\n",
      "AVG: Scores = 0.9333333333333333 F1-Scores = 0.9305977355977355\n",
      "AVG: Scores = 0.9533333333333334 F1-Scores = 0.9528619528619527\n",
      "AVG: Scores = 0.9133333333333333 F1-Scores = 0.9102009102009101\n",
      "AVG: Scores = 0.9000000000000001 F1-Scores = 0.8968098568098568\n",
      "AVG: Scores = 0.9066666666666666 F1-Scores = 0.9045130795130796\n",
      "AVG: Scores = 0.9266666666666665 F1-Scores = 0.9261279461279461\n",
      "AVG: Scores = 0.9400000000000001 F1-Scores = 0.9377526177526176\n",
      "AVG: Scores = 0.9199999999999999 F1-Scores = 0.9173761423761423\n",
      "AVG: Scores = 0.9400000000000001 F1-Scores = 0.9386868686868688\n",
      "AVG: Scores = 0.9133333333333333 F1-Scores = 0.909040589040589\n",
      "Wall time: 7h 36min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "f1scores = []\n",
    "for i_random_state in range(10, 70, 5):\n",
    "    curr_scores, curr_f1scores = executeIrisOneVsRest(random_seed=i_random_state,\n",
    "                                                classifier_function=create_and_execute_classifier_new_approach,\n",
    "                                                sigma_q_weights=[1, 1, 1, 0],\n",
    "                                                max_iter=2000,\n",
    "                                                print_each_fold_metric=False,\n",
    "                                                print_avg_metric=True)\n",
    "    scores.append(np.mean(curr_scores))\n",
    "    f1scores.append(np.mean(curr_f1scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4044424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.9199999999999999, 0.9533333333333335, 0.9333333333333333, 0.9533333333333334, 0.9133333333333333, 0.9000000000000001, 0.9066666666666666, 0.9266666666666665, 0.9400000000000001, 0.9199999999999999, 0.9400000000000001, 0.9133333333333333]\n",
      "Best score: 0.9533333333333335\n",
      "F1-Scores: [0.9176347726347727, 0.9525757575757575, 0.9305977355977355, 0.9528619528619527, 0.9102009102009101, 0.8968098568098568, 0.9045130795130796, 0.9261279461279461, 0.9377526177526176, 0.9173761423761423, 0.9386868686868688, 0.909040589040589]\n",
      "Max F1-Score: 0.9528619528619527\n"
     ]
    }
   ],
   "source": [
    "print_metrics(scores, f1scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b05fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg score: 0.9266666666666666\n",
      "Avg F1-Score: 0.9245148524315191\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg score:\", np.mean(scores))\n",
    "print(\"Avg F1-Score:\", np.mean(f1scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd66e695",
   "metadata": {},
   "source": [
    "## Different Sigma Q\n",
    "On [ICQ-Training-Estimator-New-Research Notebook](ICQ-Training-Estimator-New-Research.ipynb), the first research we do is about varying the Sigma_Q params - having different values apart from [1, 1, 1, 0] (which is the original one), and the best result we have is [1, 0, 12, 1] with highest accuracy as 0.89167 - therefore we don't expect to have an improvement right now, but we still do the test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88675ccf",
   "metadata": {},
   "source": [
    "## Integer params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff9d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: Scores = 0.8666666666666666 F1-Scores = 0.8592725792725794\n",
      "AVG: Scores = 0.8733333333333334 F1-Scores = 0.8599074999075\n",
      "AVG: Scores = 0.8866666666666667 F1-Scores = 0.8853703703703703\n",
      "AVG: Scores = 0.8866666666666667 F1-Scores = 0.88493265993266\n",
      "AVG: Scores = 0.8400000000000001 F1-Scores = 0.8186015836015835\n",
      "AVG: Scores = 0.8399999999999999 F1-Scores = 0.8346381396381396\n",
      "AVG: Scores = 0.8933333333333333 F1-Scores = 0.8837782587782588\n",
      "AVG: Scores = 0.8533333333333333 F1-Scores = 0.8457372257372258\n",
      "AVG: Scores = 0.8666666666666666 F1-Scores = 0.8603415103415104\n",
      "AVG: Scores = 0.8666666666666668 F1-Scores = 0.861099086099086\n",
      "AVG: Scores = 0.8466666666666667 F1-Scores = 0.8303705553705554\n",
      "AVG: Scores = 0.8666666666666666 F1-Scores = 0.8612319162319162\n",
      "Wall time: 4h 39min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "f1scores = []\n",
    "for i_random_state in range(10, 70, 5):\n",
    "    curr_scores, curr_f1scores = executeIrisOneVsRest(random_seed=i_random_state,\n",
    "                                                classifier_function=create_and_execute_classifier_new_approach,\n",
    "                                                sigma_q_weights=[1, 0, 12, 1],\n",
    "                                                max_iter=2000,\n",
    "                                                print_each_fold_metric=False,\n",
    "                                                print_avg_metric=True)\n",
    "    scores.append(np.mean(curr_scores))\n",
    "    f1scores.append(np.mean(curr_f1scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35c4656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.8666666666666666, 0.8733333333333334, 0.8866666666666667, 0.8866666666666667, 0.8400000000000001, 0.8399999999999999, 0.8933333333333333, 0.8533333333333333, 0.8666666666666666, 0.8666666666666668, 0.8466666666666667, 0.8666666666666666]\n",
      "Best score: 0.8933333333333333\n",
      "F1-Scores: [0.8592725792725794, 0.8599074999075, 0.8853703703703703, 0.88493265993266, 0.8186015836015835, 0.8346381396381396, 0.8837782587782588, 0.8457372257372258, 0.8603415103415104, 0.861099086099086, 0.8303705553705554, 0.8612319162319162]\n",
      "Max F1-Score: 0.8853703703703703\n",
      "Avg score: 0.8655555555555555\n",
      "Avg F1-Score: 0.8571067821067819\n"
     ]
    }
   ],
   "source": [
    "print_metrics(scores, f1scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9611631",
   "metadata": {},
   "source": [
    "## Float params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4372cfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: Scores = 0.8533333333333333 F1-Scores = 0.8420803270803271\n",
      "AVG: Scores = 0.8466666666666669 F1-Scores = 0.8334428534428534\n",
      "AVG: Scores = 0.8799999999999999 F1-Scores = 0.8736748436748437\n",
      "AVG: Scores = 0.8533333333333333 F1-Scores = 0.8252068302068303\n",
      "AVG: Scores = 0.86 F1-Scores = 0.8442809042809044\n",
      "AVG: Scores = 0.8933333333333333 F1-Scores = 0.8887963887963887\n",
      "AVG: Scores = 0.8533333333333335 F1-Scores = 0.8473990823990825\n",
      "AVG: Scores = 0.8933333333333333 F1-Scores = 0.8879968179968181\n",
      "AVG: Scores = 0.8800000000000001 F1-Scores = 0.8712086062086062\n",
      "AVG: Scores = 0.8400000000000001 F1-Scores = 0.8244192844192846\n",
      "AVG: Scores = 0.8466666666666667 F1-Scores = 0.830122655122655\n",
      "AVG: Scores = 0.8666666666666668 F1-Scores = 0.8529292929292929\n",
      "Wall time: 4h 48min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "f1scores = []\n",
    "for i_random_state in range(10, 70, 5):\n",
    "    curr_scores, curr_f1scores = executeIrisOneVsRest(random_seed=i_random_state,\n",
    "                                                classifier_function=create_and_execute_classifier_new_approach,\n",
    "                                                sigma_q_weights=[0.7, 0.0, 0.4, 0.1],\n",
    "                                                max_iter=2000,\n",
    "                                                print_each_fold_metric=False,\n",
    "                                                print_avg_metric=True)\n",
    "    scores.append(np.mean(curr_scores))\n",
    "    f1scores.append(np.mean(curr_f1scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b8eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.8533333333333333, 0.8466666666666669, 0.8799999999999999, 0.8533333333333333, 0.86, 0.8933333333333333, 0.8533333333333335, 0.8933333333333333, 0.8800000000000001, 0.8400000000000001, 0.8466666666666667, 0.8666666666666668]\n",
      "Best score: 0.8933333333333333\n",
      "F1-Scores: [0.8420803270803271, 0.8334428534428534, 0.8736748436748437, 0.8252068302068303, 0.8442809042809044, 0.8887963887963887, 0.8473990823990825, 0.8879968179968181, 0.8712086062086062, 0.8244192844192846, 0.830122655122655, 0.8529292929292929]\n",
      "Max F1-Score: 0.8887963887963887\n",
      "Avg score: 0.8638888888888889\n",
      "Avg F1-Score: 0.8517964905464904\n"
     ]
    }
   ],
   "source": [
    "print_metrics(scores, f1scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41878bfb",
   "metadata": {},
   "source": [
    "## Search results for Learning Rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "916374bc",
   "metadata": {},
   "source": [
    "## Small subset of learning rates\n",
    "The very first result we get is learning_rate = 0.001, which is different from the article's best 0.01. Let's see how our model deals with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5175e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: Scores = 0.9066666666666666 F1-Scores = 0.9056228956228957\n",
      "AVG: Scores = 0.9533333333333334 F1-Scores = 0.9524410774410775\n",
      "AVG: Scores = 0.9400000000000001 F1-Scores = 0.9386868686868686\n",
      "AVG: Scores = 0.9200000000000002 F1-Scores = 0.919040404040404\n",
      "AVG: Scores = 0.8866666666666667 F1-Scores = 0.8801394901394902\n",
      "AVG: Scores = 0.9400000000000001 F1-Scores = 0.9391750841750841\n",
      "AVG: Scores = 0.9533333333333334 F1-Scores = 0.9524410774410773\n",
      "AVG: Scores = 0.9400000000000001 F1-Scores = 0.9382491582491582\n",
      "AVG: Scores = 0.96 F1-Scores = 0.9588720538720539\n",
      "AVG: Scores = 0.9533333333333334 F1-Scores = 0.9533164983164983\n",
      "AVG: Scores = 0.9333333333333333 F1-Scores = 0.9305977355977355\n",
      "AVG: Scores = 0.9466666666666667 F1-Scores = 0.9463299663299664\n",
      "Wall time: 4h 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "f1scores = []\n",
    "for i_random_state in range(10, 70, 5):\n",
    "    curr_scores, curr_f1scores = executeIrisOneVsRest(random_seed=i_random_state,\n",
    "                                                classifier_function=create_and_execute_classifier_new_approach,\n",
    "                                                sigma_q_weights=[1, 1, 1, 0],\n",
    "                                                max_iter=2000,\n",
    "                                                print_each_fold_metric=False,\n",
    "                                                print_avg_metric=True,\n",
    "                                                learning_rate=0.001)\n",
    "    scores.append(np.mean(curr_scores))\n",
    "    f1scores.append(np.mean(curr_f1scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f334753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.9066666666666666, 0.9533333333333334, 0.9400000000000001, 0.9200000000000002, 0.8866666666666667, 0.9400000000000001, 0.9533333333333334, 0.9400000000000001, 0.96, 0.9533333333333334, 0.9333333333333333, 0.9466666666666667]\n",
      "Best score: 0.96\n",
      "F1-Scores: [0.9056228956228957, 0.9524410774410775, 0.9386868686868686, 0.919040404040404, 0.8801394901394902, 0.9391750841750841, 0.9524410774410773, 0.9382491582491582, 0.9588720538720539, 0.9533164983164983, 0.9305977355977355, 0.9463299663299664]\n",
      "Max F1-Score: 0.9588720538720539\n"
     ]
    }
   ],
   "source": [
    "print_metrics(scores, f1scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf72809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg score: 0.9361111111111112\n",
      "Avg F1-Score: 0.9345760258260257\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg score:\", np.mean(scores))\n",
    "print(\"Avg F1-Score:\", np.mean(f1scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44ab734d",
   "metadata": {},
   "source": [
    "It seems that we managed to improve a bit more our model, as our first result was avg score 0.9266 and now we got 0.9361 - almost 1% more. Let's keep researching!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4edfe34",
   "metadata": {},
   "source": [
    "## Biggest subset of learning rates\n",
    "After our big research on [ICQ-Training-Estimator-New-Research Notebook](ICQ-Training-Estimator-New-Research.ipynb), we reached the conclusion that the learning rate of 0.0008 was the best one, which is quite close to the 0.001 that we tried before, so it's expected little to none improvement in our tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG: Scores = 0.9200000000000002 F1-Scores = 0.9188047138047137\n",
      "AVG: Scores = 0.9533333333333334 F1-Scores = 0.9533346283346283\n",
      "AVG: Scores = 0.9533333333333334 F1-Scores = 0.9527104377104377\n",
      "AVG: Scores = 0.9266666666666665 F1-Scores = 0.9238637288637289\n",
      "AVG: Scores = 0.8866666666666667 F1-Scores = 0.8805603655603657\n",
      "AVG: Scores = 0.9466666666666667 F1-Scores = 0.9458417508417508\n",
      "AVG: Scores = 0.9466666666666667 F1-Scores = 0.9457070707070706\n",
      "AVG: Scores = 0.9400000000000001 F1-Scores = 0.9391750841750841\n",
      "AVG: Scores = 0.9533333333333334 F1-Scores = 0.9521380471380472\n",
      "AVG: Scores = 0.9400000000000001 F1-Scores = 0.9397811447811447\n",
      "AVG: Scores = 0.9 F1-Scores = 0.8972138972138971\n",
      "AVG: Scores = 0.9466666666666667 F1-Scores = 0.9461952861952861\n",
      "Wall time: 5h 37min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "f1scores = []\n",
    "for i_random_state in range(10, 70, 5):\n",
    "    curr_scores, curr_f1scores = executeIrisOneVsRest(random_seed=i_random_state,\n",
    "                                                classifier_function=create_and_execute_classifier_new_approach,\n",
    "                                                sigma_q_weights=[1, 1, 1, 0],\n",
    "                                                max_iter=2000,\n",
    "                                                print_each_fold_metric=False,\n",
    "                                                print_avg_metric=True,\n",
    "                                                learning_rate=0.0008)\n",
    "    scores.append(np.mean(curr_scores))\n",
    "    f1scores.append(np.mean(curr_f1scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6096bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.9200000000000002, 0.9533333333333334, 0.9533333333333334, 0.9266666666666665, 0.8866666666666667, 0.9466666666666667, 0.9466666666666667, 0.9400000000000001, 0.9533333333333334, 0.9400000000000001, 0.9, 0.9466666666666667]\n",
      "Best score: 0.9533333333333334\n",
      "F1-Scores: [0.9188047138047137, 0.9533346283346283, 0.9527104377104377, 0.9238637288637289, 0.8805603655603657, 0.9458417508417508, 0.9457070707070706, 0.9391750841750841, 0.9521380471380472, 0.9397811447811447, 0.8972138972138971, 0.9461952861952861]\n",
      "Max F1-Score: 0.9533346283346283\n"
     ]
    }
   ],
   "source": [
    "print_metrics(scores, f1scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aecfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg score: 0.9344444444444445\n",
      "Avg F1-Score: 0.9329438462771796\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg score:\", np.mean(scores))\n",
    "print(\"Avg F1-Score:\", np.mean(f1scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8529fa0e",
   "metadata": {},
   "source": [
    "As expected, we got no improvement in our average test whatsoever, which means our current best result is:\n",
    "- Sigma Q params = [1, 1, 1, 0]\n",
    "- Learning rate = 0.001\n",
    "- \\# of training epochs = 2000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
