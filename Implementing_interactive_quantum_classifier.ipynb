{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5J1AkiSErOm8"
      },
      "outputs": [],
      "source": [
        "#code of Interactive Quantum Classifier Inspired by Quantum Open System Theory\n",
        "#LINK https://ieeexplore.ieee.org/document/9533917\n",
        "\n",
        "#LINK https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9533917\n",
        "\n",
        "#this code was written by Fernando Maciano de Paula Neto (fernando@cin.ufpe.br) and Eduardo Barreto Brito (ebb2@cin.ufpe.br)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "from helpers.icq_methods import create_and_execute_classifier, get_sigmaQ, get_sigmaE, get_U_operator, get_p, update_weights\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_and_execute_classifiers(vectorX, vectorWs):\n",
        "  \"\"\"\n",
        "    Creates classifiers with differents weights and outputs the index of\n",
        "    the weight that has the highest probability of having class 1\n",
        "  \"\"\"\n",
        "  list_p11_i = []\n",
        "\n",
        "  for vectorWs_i in vectorWs:\n",
        "    # First we create and execute the classifier\n",
        "    zi, p11_i = create_and_execute_classifier(vectorX, vectorWs_i)  \n",
        "\n",
        "    # Then we save the probability of being class 1\n",
        "    list_p11_i.append(p11_i)\n",
        "  \n",
        "  # Finally, we get the biggest prob\n",
        "  return np.argmax(list_p11_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_and_execute_1_classifier(X, Y, w, n=0.1):\n",
        "  \"\"\"\"\n",
        "    Creates, train and executes 1 classifier throughout all instances,\n",
        "    updating the weights instance per instance (batch-size = 1).\n",
        "   \n",
        "    X is a NxM vector of Atributes\n",
        "    Y is the N vector of Classes\n",
        "    W is the M vector of Weights\n",
        "    N is the learning rate\n",
        "    \n",
        "    Returns updated_weight, error\n",
        "  \"\"\"\n",
        "  error = 0\n",
        "  \n",
        "  for x,y in zip(X,Y):\n",
        "    # First we create and execute the classifier\n",
        "    z, p11 = create_and_execute_classifier(x,w)\n",
        "\n",
        "    # Then we update our weights based on our result\n",
        "    w = update_weights(w,y,z,x,p11,n)\n",
        "\n",
        "    # Next we store the error\n",
        "    if (z != y):\n",
        "      error += 1\n",
        "\n",
        "  return w, error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_1_batch_classifier(X, Y, w, n=0.1):\n",
        "  \"\"\"\n",
        "    Creates, trains and executes 1 classifier after all instances using the average\n",
        "    of the input vector (X), class vector (Y), probability of being class 1 and assigned\n",
        "    class (uses updates_weights(w,y_avg,z_avg,x_avg,p11_avg,n)).\n",
        "    \n",
        "    X is a NxM vector of Atributes\n",
        "    Y is the N vector of Classes\n",
        "    W is the M vector of Weights\n",
        "    N is the learning rate\n",
        "\n",
        "    Returns updated_weight, error\n",
        "  \"\"\"\n",
        "  error = 0\n",
        "  x_avg = 0\n",
        "  y_avg = 0\n",
        "  z_avg = 0\n",
        "  p11_avg = 0\n",
        "  lines = X.shape[0]\n",
        "\n",
        "  # We do something similar to create_and_execute_1_classifier method, but updating only once\n",
        "  for x,y in zip(X,Y):\n",
        "    z, p11 = create_and_execute_classifier(x,w)\n",
        "    x_avg += x/lines\n",
        "    y_avg += y/lines\n",
        "    z_avg += z/lines\n",
        "    p11_avg += p11/lines\n",
        "    if (z != y):\n",
        "      error += 1\n",
        "\n",
        "  w = update_weights(w,y_avg,z_avg,x_avg,p11_avg,n)\n",
        "\n",
        "  return w, error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_n_steps_classifier(X, Y, w, batch_size, Nsteps, n=0.1, stop_error_zero=False):\n",
        "  \"\"\"\n",
        "    Creates, trains and executes classifiers through batches using @training_1_batch_classifier method.\n",
        "    \n",
        "    X is a NxM vector of Atributes\n",
        "    Y is the N vector of Classes\n",
        "    w is the M vector of Weights\n",
        "    batch_size is the number of instances used per batch training\n",
        "    Nsteps is the number of times the classifier will be training. Similar to number of epochs\n",
        "    n is the learning rate\n",
        "    stop_error_zero defines whether we should stop when we have error equals zero\n",
        "\n",
        "    Returns the weights after the training and the min error obtained after executing\n",
        "  \"\"\"\n",
        "  # First we need to know how many batches we will have for training\n",
        "  lines = X.shape[0]\n",
        "  splits = math.ceil(lines / batch_size)\n",
        "  \n",
        "  min_error = np.Inf\n",
        "  min_w_error = np.Inf\n",
        "  for i in range(Nsteps):\n",
        "    errors = 0\n",
        "    # For each batch split, we need to train our classfier\n",
        "    for split in range(splits):\n",
        "      # First step is to define our dataset\n",
        "      X_batch = X[split*batch_size:(split+1)*batch_size , :]\n",
        "      Y_batch = Y[split*batch_size:(split+1)*batch_size]\n",
        "\n",
        "      # We save the weights in which we're executing the current classifier in case this is the best one\n",
        "      w_old = w[:]\n",
        "\n",
        "      # Then we train and classify for this part of the dataset\n",
        "      w, error = training_1_batch_classifier(X_batch,Y_batch,w=w,n=n)\n",
        "      errors += error\n",
        "    \n",
        "    # and save the sum of errors for all batches if needed \n",
        "    if (min_error > errors):\n",
        "      min_w_error = w_old\n",
        "      min_error = errors\n",
        "      \n",
        "    if (errors == 0 and stop_error_zero):\n",
        "      break\n",
        "  return min_w_error, min_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def replicate_classes(data_set, features_names, classes):\n",
        "  \"\"\"\n",
        "    Creates datasets which assigns 1 to one class and 0 to another, and balance\n",
        "    the number of instances of class 0 and class 1.\n",
        "    \n",
        "    Returns an array with all datasets. For Iris dataset\n",
        "    list_x_y[0] = datasets where all instances of class 0 has class 1 and instances of other classes has class 0\n",
        "    list_x_y[1] = datasets where all instances of class 1 has class 1 and instances of other classes has class 0\n",
        "    list_x_y[2] = datasets where all instances of class 2 has class 1 and instances of other classes has class 0\n",
        "    \n",
        "    It also duplicates the instances with the targeted class, making all datasets having 100 instances of class 0\n",
        "    and 100 instances of class 1 for Iris dataset.\n",
        "  \"\"\"\n",
        "  list_x_y = []\n",
        "  n_classes = len(classes)\n",
        "\n",
        "  for class_i in classes:\n",
        "    # We don't want to change the original dataset, so we make a copy of it\n",
        "    y_class_i = data_set.copy()\n",
        "\n",
        "    # First we change all classes to n + 1, in order for it to have a special value\n",
        "    y_class_i.loc[ y_class_i[\"target\"] == class_i  , \"target\"]  = n_classes+1\n",
        "\n",
        "    # Then, we change every class different from the one we want to 0\n",
        "    y_class_i.loc[ y_class_i[\"target\"] < n_classes  , \"target\"]  = 0\n",
        "\n",
        "    # Finally, we change every class that is equal to the one we want to 1\n",
        "    y_class_i.loc[ y_class_i[\"target\"] == (n_classes+1)  , \"target\"]  = 1\n",
        "\n",
        "    # Last but not least, we replicate the dataset to have a balanced number of instances with\n",
        "    # desired and undesired classes. As we're dealing only with Iris, which has 50/50/50, we only\n",
        "    # need to replicate once\n",
        "    y_class_i = pd.concat([y_class_i, y_class_i[y_class_i[\"target\"]==1]], axis=0)\n",
        "  \n",
        "    # Now we split between attributes and target\n",
        "    list_x_y.append([y_class_i[features_names], y_class_i[\"target\"]])\n",
        "\n",
        "  return list_x_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_many_classifiers(X, y, list_of_weights_classifiers):\n",
        "  \"\"\"\n",
        "    Uses the classifier weights to try to predict the correct class and then prints the metrics\n",
        "\n",
        "    Returns precision, recall, f1_measure, accuracy, y_pred\n",
        "  \"\"\"\n",
        "  lines = X.shape[0]\n",
        "  y_pred = []\n",
        "\n",
        "  # For each instance, we try to predict the correct class\n",
        "  for i in range(lines):\n",
        "    output_class = create_and_execute_classifiers(X.iloc[i, :].values, list_of_weights_classifiers)\n",
        "    y_pred.append(output_class)\n",
        "  \n",
        "  # Then we get the correct classes to start recording\n",
        "  y_true = y[\"target\"].tolist()\n",
        "\n",
        "  # To do so, we count the number of hits\n",
        "  hit=0\n",
        "  for y, yhat in zip(y_true, y_pred):\n",
        "    if (y == yhat):\n",
        "      hit+=1\n",
        "\n",
        "  # Finally, we calculate every score we need\n",
        "  precision = precision_score(y_true, y_pred, labels=[0,1,2], average='micro')\n",
        "  recall = recall_score(y_true, y_pred, labels=[0,1,2],average='micro')\n",
        "  f1_measure = f1_score(y_true, y_pred, labels=[0,1,2], average='micro')\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "  return precision, recall, f1_measure, accuracy, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def avg_metrics(measures):\n",
        "  \"\"\" \n",
        "    Prints the average of the execution portraid in measures.\n",
        "    The \"measures\" param must be a vector of the following tuple:\n",
        "    (precision, recall, f1_measure, accuracy)\n",
        "  \"\"\"\n",
        "  precisions = 0\n",
        "  recalls = 0\n",
        "  f1_measures = 0\n",
        "  accs = 0\n",
        "  count = 0\n",
        "\n",
        "  for precision, recall, f1_measure, accuracy in measures:\n",
        "    precisions += precision\n",
        "    recalls += recall\n",
        "    f1_measures += f1_measure\n",
        "    accs += accuracy\n",
        "    count+=1\n",
        "    \n",
        "  print(\"acc\", accs/count)\n",
        "  print(\"precision\", precisions/count)\n",
        "  print(\"recall\", recalls/count)\n",
        "  print(\"f1_measure\", f1_measures/count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standard_scaling(x_train, x_test):\n",
        "    \"\"\"\n",
        "        Uses the scikit-learn StandardScaler to normalize the dataset. \n",
        "        See https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "\n",
        "        It also uses the same normalizing factor on x_test.\n",
        "    \"\"\"\n",
        "    x_train_copy = x_train.copy()\n",
        "    x_test_copy = x_test.copy()\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(x_train_copy)\n",
        "    \n",
        "    x_train_copy = scaler.transform(x_train_copy)\n",
        "    x_test_copy = scaler.transform(x_test_copy)\n",
        "\n",
        "    iris = datasets.load_iris(as_frame=True)\n",
        "\n",
        "    x_train_copy = pd.DataFrame(x_train_copy, columns = iris['feature_names'])\n",
        "    x_test_copy = pd.DataFrame(x_test_copy, columns = iris['feature_names'])\n",
        "\n",
        "    return x_train_copy, x_test_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def maximum_absolute_scaling_by_column(x_train, x_test):\n",
        "    \"\"\"\n",
        "        Divides the whole column by the max absolute value available.\n",
        "        \n",
        "        It also uses the same normalizing factor on x_test.\n",
        "    \"\"\"\n",
        "    # copy the dataframe\n",
        "    x_train_copy = x_train.copy()\n",
        "    x_test_copy = x_test.copy()\n",
        "    \n",
        "    # apply maximum absolute scaling\n",
        "    for column in x_train_copy.columns:\n",
        "        col_abs_max = x_train_copy[column].abs().max()\n",
        "        \n",
        "        x_train_copy[column] = x_train_copy[column]  / col_abs_max\n",
        "        x_test_copy[column] = x_test_copy[column]  / col_abs_max\n",
        "    \n",
        "    return x_train_copy, x_test_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def min_max_scaling_by_column(x_train, x_test):\n",
        "    \"\"\"\n",
        "        Divides the whole column by the difference between its max and min values.\n",
        "\n",
        "        It also uses the same normalizing factor on x_test.\n",
        "    \"\"\"\n",
        "    # copy the dataframe\n",
        "    x_train_copy = x_train.copy()\n",
        "    x_test_copy = x_test.copy()\n",
        "    \n",
        "    # apply min-max scaling\n",
        "    for column in x_train_copy.columns:\n",
        "        col_min = x_train_copy[column].min()\n",
        "        col_max = x_train_copy[column].max()\n",
        "\n",
        "        x_train_copy[column] = (x_train_copy[column] - col_min) / (col_max - col_min)\n",
        "        x_test_copy[column] = (x_test_copy[column] - col_min) / (col_max - col_min)\n",
        "        \n",
        "    return x_train_copy, x_test_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hjrH_WOzje1G"
      },
      "outputs": [],
      "source": [
        "def min_max_scaling_by_column_type_2(x_train, x_test):\n",
        "    \"\"\"\n",
        "        Divides the whole column through the following equation:\n",
        "        column = (value - min) / (max - min) - 1\n",
        "\n",
        "        It also uses the same normalizing factor on x_test.\n",
        "    \"\"\"\n",
        "    # copy the dataframe\n",
        "    a, b = -1, 0\n",
        "    x_train_copy = x_train.copy()\n",
        "    x_test_copy = x_test.copy()\n",
        "    \n",
        "    # apply min-max scaling\n",
        "    for column in x_train_copy.columns:\n",
        "        col_min = x_train_copy[column].min()\n",
        "        col_max = x_train_copy[column].max()\n",
        "        \n",
        "        x_train_copy[column] =(b-a)*(x_train_copy[column] - col_min) / (col_max - col_min) + a\n",
        "        x_test_copy[column] =(b-a)*(x_test_copy[column] - col_min) / (col_max - col_min) + a\n",
        "        \n",
        "    return x_train_copy, x_test_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_k_fold_classifier(kfold, \n",
        "                              X, \n",
        "                              y, \n",
        "                              Nsteps, \n",
        "                              batch_size, \n",
        "                              n_learning_rate, \n",
        "                              features_names, \n",
        "                              classes, \n",
        "                              normalizing_function=min_max_scaling_by_column_type_2, \n",
        "                              random_state=42, \n",
        "                              print_error_binary_dataset=False, \n",
        "                              print_metrics_per_fold=True):\n",
        "    # Instantiating the K-Fold cross validation object with 5 folds\n",
        "    k_folds = StratifiedKFold(n_splits = kfold, shuffle = True, random_state = random_state)\n",
        "    metrics = []\n",
        "\n",
        "    # Iterating through each of the folds in K-Fold\n",
        "    for train_index, test_index in tqdm(k_folds.split(X, y), total=(kfold), desc=\"Training model\"):\n",
        "      # Splitting the training set from the validation set for this specific fold\n",
        "      X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
        "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "      # Applies the normalizing_function on each Dataset\n",
        "      X_train, X_test = normalizing_function(X_train, X_test)\n",
        "      \n",
        "      # We create a new Pandas dataset\n",
        "      dataset = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "      # This list contains 3 values, each one being a dataset for each class\n",
        "      # of the iris dataset. See @replicate_classes doc\n",
        "      list_of_x_y = replicate_classes(dataset, features_names, classes)\n",
        "      list_of_trainned_w = []\n",
        "      count=0\n",
        "\n",
        "      # Then, for each dataset of each class, we train our model\n",
        "      for Xi, yi in list_of_x_y:\n",
        "        # We initialize the weights vector with values 0.1. \n",
        "        # The number of rows must be the number of attributes, as it is a diagonal matrix\n",
        "        w = [0.1 for i in range(Xi.shape[1])]\n",
        "\n",
        "        # Now we need to convert our datasets into np arrays, as it's the type expected in the training_n_steps_classifier\n",
        "        X_train = np.array(Xi)\n",
        "        y_train = np.array(yi)\n",
        "\n",
        "        # Now we update our weights and save the error for printing\n",
        "        wi, error = training_n_steps_classifier(X_train,y_train, w, Nsteps=Nsteps, batch_size=batch_size, n=n_learning_rate, stop_error_zero=True)\n",
        "        if print_error_binary_dataset:\n",
        "          print(\"error #\", count, error)\n",
        "\n",
        "        list_of_trainned_w.append(wi)\n",
        "        count+=1\n",
        "\n",
        "      # For testing, we try every weights we already had before, in order to find the best one\n",
        "      precision, recall, f1_measure, accuracy, y_pred = test_many_classifiers(X_test , y_test, list_of_trainned_w)\n",
        "\n",
        "      # And then we append the metrics for this specific execution\n",
        "      metrics.append([precision, recall, f1_measure, accuracy])\n",
        "\n",
        "      if print_metrics_per_fold:\n",
        "        print(\"Métricas (precision, recall, f1_measure, accuracy):\", metrics[-1])\n",
        "\n",
        "    return list_of_trainned_w, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZCncDOxkbWG",
        "outputId": "5606c945-63ee-4286-a341-a2bfac3d2553"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c176583674f74fa59f552791d39e336e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training model:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metricas, precision, recall, f1_measure, acc [0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667]\n",
            "metricas, precision, recall, f1_measure, acc [0.8, 0.8, 0.8000000000000002, 0.8]\n",
            "metricas, precision, recall, f1_measure, acc [0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333]\n",
            "metricas, precision, recall, f1_measure, acc [0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333]\n",
            "metricas, precision, recall, f1_measure, acc [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]\n",
            "metricas, precision, recall, f1_measure, acc [0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333]\n",
            "metricas, precision, recall, f1_measure, acc [0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667]\n",
            "metricas, precision, recall, f1_measure, acc [0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333]\n",
            "metricas, precision, recall, f1_measure, acc [0.8, 0.8, 0.8000000000000002, 0.8]\n",
            "metricas, precision, recall, f1_measure, acc [0.4666666666666667, 0.4666666666666667, 0.4666666666666667, 0.4666666666666667]\n"
          ]
        }
      ],
      "source": [
        "# Now that we have built all methods, we can have our training\n",
        "\n",
        "# First thing is to load the iris dataset from sklearn\n",
        "iris = datasets.load_iris(as_frame=True)\n",
        "\n",
        "# Then we get our X and Y\n",
        "X_iris = pd.DataFrame(data= iris['data'],\n",
        "                      columns= iris['feature_names'])\n",
        "y_iris = pd.DataFrame(data= iris['target'],\n",
        "                      columns= ['target'])\n",
        "\n",
        "# And then execute it\n",
        "list_of_trainned_w, metrics = training_k_fold_classifier(kfold=10, \n",
        "                                                            X=X_iris, \n",
        "                                                            y=y_iris, \n",
        "                                                            Nsteps=2000, \n",
        "                                                            batch_size=60, \n",
        "                                                            n_learning_rate=0.009,\n",
        "                                                            features_names=iris['feature_names'], \n",
        "                                                            classes=[0,1,2],\n",
        "                                                            normalizing_function=min_max_scaling_by_column_type_2,\n",
        "                                                            random_state=42) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rThlHhe9Btu",
        "outputId": "16b0e8cd-c8ff-4a1c-8ca2-0b2e5be9391a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc 0.74\n",
            "precision 0.74\n",
            "recall 0.74\n",
            "f1_measure 0.74\n"
          ]
        }
      ],
      "source": [
        "# Most important part - what are our metrics?\n",
        "avg_metrics(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28add0c343d947efa74b797a071f9a1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training model:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metricas, precision, recall, f1_measure, acc [0.8, 0.8, 0.8000000000000002, 0.8]\n",
            "metricas, precision, recall, f1_measure, acc [0.6, 0.6, 0.6, 0.6]\n",
            "metricas, precision, recall, f1_measure, acc [0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333]\n",
            "metricas, precision, recall, f1_measure, acc [0.4666666666666667, 0.4666666666666667, 0.4666666666666667, 0.4666666666666667]\n",
            "metricas, precision, recall, f1_measure, acc [0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333]\n",
            "metricas, precision, recall, f1_measure, acc [0.8, 0.8, 0.8000000000000002, 0.8]\n",
            "metricas, precision, recall, f1_measure, acc [0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333]\n",
            "metricas, precision, recall, f1_measure, acc [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]\n",
            "metricas, precision, recall, f1_measure, acc [0.6, 0.6, 0.6, 0.6]\n",
            "metricas, precision, recall, f1_measure, acc [0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333]\n"
          ]
        }
      ],
      "source": [
        "# Now that we have built all methods, we can have our training\n",
        "\n",
        "# First thing is to load the iris dataset from sklearn\n",
        "iris = datasets.load_iris(as_frame=True)\n",
        "\n",
        "# Then we get our X and Y\n",
        "X_iris = pd.DataFrame(data= iris['data'],\n",
        "                      columns= iris['feature_names'])\n",
        "y_iris = pd.DataFrame(data= iris['target'],\n",
        "                      columns= ['target'])\n",
        "\n",
        "# And then execute it\n",
        "list_of_trainned_w, metrics = training_k_fold_classifier(kfold=10, \n",
        "                                                            X=X_iris, \n",
        "                                                            y=y_iris, \n",
        "                                                            Nsteps=2000, \n",
        "                                                            batch_size=60, \n",
        "                                                            n_learning_rate=0.009,\n",
        "                                                            features_names=iris['feature_names'], \n",
        "                                                            classes=[0,1,2],\n",
        "                                                            normalizing_function=min_max_scaling_by_column,\n",
        "                                                            random_state=42) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc 0.6866666666666668\n",
            "precision 0.6866666666666668\n",
            "recall 0.6866666666666668\n",
            "f1_measure 0.6866666666666668\n"
          ]
        }
      ],
      "source": [
        "# Most important part - what are our metrics?\n",
        "avg_metrics(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfe5ec3143974bfebb09e922281be627",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training model:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metricas, precision, recall, f1_measure, acc [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "metricas, precision, recall, f1_measure, acc [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]\n",
            "metricas, precision, recall, f1_measure, acc [0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333]\n",
            "metricas, precision, recall, f1_measure, acc [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]\n",
            "metricas, precision, recall, f1_measure, acc [0.6, 0.6, 0.6, 0.6]\n",
            "metricas, precision, recall, f1_measure, acc [0.4, 0.4, 0.4000000000000001, 0.4]\n",
            "metricas, precision, recall, f1_measure, acc [0.8, 0.8, 0.8000000000000002, 0.8]\n",
            "metricas, precision, recall, f1_measure, acc [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]\n",
            "metricas, precision, recall, f1_measure, acc [0.4, 0.4, 0.4000000000000001, 0.4]\n",
            "metricas, precision, recall, f1_measure, acc [0.6, 0.6, 0.6, 0.6]\n"
          ]
        }
      ],
      "source": [
        "# Now that we have built all methods, we can have our training\n",
        "\n",
        "# First thing is to load the iris dataset from sklearn\n",
        "iris = datasets.load_iris(as_frame=True)\n",
        "\n",
        "# Then we get our X and Y\n",
        "X_iris = pd.DataFrame(data= iris['data'],\n",
        "                      columns= iris['feature_names'])\n",
        "y_iris = pd.DataFrame(data= iris['target'],\n",
        "                      columns= ['target'])\n",
        "\n",
        "# And then execute it\n",
        "list_of_trainned_w, metrics = training_k_fold_classifier(kfold=10, \n",
        "                                                            X=X_iris, \n",
        "                                                            y=y_iris, \n",
        "                                                            Nsteps=2000, \n",
        "                                                            batch_size=60, \n",
        "                                                            n_learning_rate=0.009,\n",
        "                                                            features_names=iris['feature_names'], \n",
        "                                                            classes=[0,1,2],\n",
        "                                                            normalizing_function=maximum_absolute_scaling_by_column,\n",
        "                                                            random_state=42) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc 0.5666666666666667\n",
            "precision 0.5666666666666667\n",
            "recall 0.5666666666666667\n",
            "f1_measure 0.5666666666666667\n"
          ]
        }
      ],
      "source": [
        "# Most important part - what are our metrics?\n",
        "avg_metrics(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7f7c38fbea5419991c778fb9d7deda9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training model:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
            "Métricas (precision, recall, f1_measure, accuracy): [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n"
          ]
        }
      ],
      "source": [
        "# Now that we have built all methods, we can have our training\n",
        "\n",
        "# First thing is to load the iris dataset from sklearn\n",
        "iris = datasets.load_iris(as_frame=True)\n",
        "\n",
        "# Then we get our X and Y\n",
        "X_iris = pd.DataFrame(data= iris['data'],\n",
        "                      columns= iris['feature_names'])\n",
        "y_iris = pd.DataFrame(data= iris['target'],\n",
        "                      columns= ['target'])\n",
        "\n",
        "# And then execute it\n",
        "list_of_trainned_w, metrics = training_k_fold_classifier(kfold=10, \n",
        "                                                            X=X_iris, \n",
        "                                                            y=y_iris, \n",
        "                                                            Nsteps=2000, \n",
        "                                                            batch_size=60, \n",
        "                                                            n_learning_rate=0.009,\n",
        "                                                            features_names=iris['feature_names'], \n",
        "                                                            classes=[0,1,2],\n",
        "                                                            normalizing_function=standard_scaling,\n",
        "                                                            random_state=42) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc 0.33333333333333337\n",
            "precision 0.33333333333333337\n",
            "recall 0.33333333333333337\n",
            "f1_measure 0.33333333333333337\n"
          ]
        }
      ],
      "source": [
        "# Most important part - what are our metrics?\n",
        "avg_metrics(metrics)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
